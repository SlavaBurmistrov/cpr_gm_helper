{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pymupdf\n",
    "import re,uuid\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Core Book Embedding",
   "id": "56c79f69810e2fca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "core_book = pymupdf.open(\"Cyberpunk Red Core.pdf\")\n",
    "client_open_ai = OpenAI(api_key= \"\")"
   ],
   "id": "b95cd540e359624c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Core Book RAG\n",
    "def core_book_rag(core_book_pdf):\n",
    "    collection_name = \"cpr_core_rules\"\n",
    "    rag_model_name = \"all-MiniLM-L6-v2\"\n",
    "    chromadb_path = \"./vectordb\"\n",
    "    # Breaks the book down into page map with Chapter Title and Pages\n",
    "    core_book = pymupdf.open(core_book_pdf)\n",
    "    chunks = []\n",
    "    toc = core_book.get_toc(simple=True)\n",
    "    page_map = {}\n",
    "    toc_index = 0\n",
    "    for page_num in range(len(core_book)):\n",
    "            while toc_index + 1 < len(toc) and toc[toc_index + 1][2] <= page_num + 1:\n",
    "                toc_index += 1\n",
    "            page_map[page_num] = toc[toc_index][1] if toc else \"Unknown\"\n",
    "    for page_num in range(len(core_book)):\n",
    "        page = core_book.load_page(page_num)\n",
    "        text = page.get_text(\"text\")\n",
    "        chapter = page_map.get(page_num, \"Unknown\")\n",
    "\n",
    "        paragraphs = re.split(r\"\\n{2,}\", text)\n",
    "        for para in paragraphs:\n",
    "            clean = para.strip()\n",
    "            if len(clean) > 30:\n",
    "                chunks.append({\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"text\": clean,\n",
    "                    \"meta\": {\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"chapter\": chapter\n",
    "                    }\n",
    "                })\n",
    "    rag_model = SentenceTransformer(rag_model_name)\n",
    "    chroma_client = chromadb.PersistentClient(path=chromadb_path)\n",
    "    collection = chroma_client.get_or_create_collection(collection_name)\n",
    "\n",
    "    print(f\"Embedding {len(chunks)} chunks...\")\n",
    "    for chunk in tqdm(chunks):\n",
    "        emb = rag_model.encode(chunk[\"text\"]).tolist()\n",
    "        collection.add(\n",
    "            ids=[chunk[\"id\"]],\n",
    "            embeddings=[emb],\n",
    "            documents=[chunk[\"text\"]],\n",
    "            metadatas=[chunk[\"meta\"]]\n",
    "        )"
   ],
   "id": "9d0406e3e6546719",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def query_chroma(collection: str, query: str, k=5):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./vectordb\")\n",
    "    collection = chroma_client.get_collection(collection)\n",
    "\n",
    "    query_emb = model.encode(query).tolist()\n",
    "    results = collection.query(query_embeddings=[query_emb], n_results=k)\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"text\": doc,\n",
    "            \"page\": meta[\"page\"],\n",
    "            \"chapter\": meta[\"chapter\"]\n",
    "        }\n",
    "        for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0])\n",
    "    ]"
   ],
   "id": "ff4fe4027ebfb4d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for result in query_chroma(\"cpr_core_rules\", \"What are the rules for cover?\"):\n",
    "    pprint.pprint(result)"
   ],
   "id": "74d3685ee4a668c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ask_gpt4o_with_rag(user_query: str, temp=0.4):\n",
    "    relevant_rules = query_chroma(\"cpr_core_rules\",user_query)\n",
    "    context_text = \"\\n\\n\".join(\n",
    "        f\"[{r['chapter']} – p.{r['page']}]\\n{r['text']}\" for r in relevant_rules\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a Cyberpunk RED game assistant. Answer the user's question \"\n",
    "                \"using only the official rules. Include relevant citations (e.g., page number and chapter). \"\n",
    "                \"If the rules are unclear, say so rather than guessing.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{user_query}\\n\\nRelevant Rules:\\n{context_text}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client_open_ai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=temp\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ],
   "id": "21e7a47853339746",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "answer = ask_gpt4o_with_rag(\"How can I generate a net architecture?\")\n",
    "print(answer)"
   ],
   "id": "83f50fb02fcb4ac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## WORLD GENERATION",
   "id": "d6a265cff2d44551"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "atlas = pymupdf.open(\"NightCityAtlas Copy.pdf\")\n",
    "world_state = {\"locations\": {}, \"factions\": {}}\n",
    "current_location = None\n",
    "# Basic regex patterns\n",
    "location_header = re.compile(r\"^(.+?)\\s+\\((\\w)\\)$\")  # e.g., Little Europe (A)\n",
    "sublocation_header = re.compile(r\"^\\((\\w\\d+)\\)\\s(.+?):?\\s\")\n",
    "manager_pattern = re.compile(r\"City Manager:\\s(.+)\")\n",
    "security_pattern = re.compile(r\"Security Provider:\\s(.+)\")\n",
    "gangs_pattern = re.compile(r\"Gangs Present:\\s(.+)\")"
   ],
   "id": "4fbf650e965094cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_FILE = \"NightCityAtlas.txt\"\n",
    "OUTPUT_FILE = \"campaign/world_state.json\"\n",
    "\n",
    "def parse_world_text_upper(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [line.strip().upper() for line in f if line.strip()]\n",
    "\n",
    "    world = {\"locations\": {}}\n",
    "    current_region = None\n",
    "    current_location = None\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        # Match global region: ##GLOBAL LOCATION##\n",
    "        if re.match(r\"^##.+##$\", line):\n",
    "            current_region = line.strip(\"#\").strip()\n",
    "            i += 1  # Skip region description or next line\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Match location line like \"LITTLE EUROPE (A)\"\n",
    "        location_match = re.match(r\"^(.*?)\\s+\\([A-Z]\\)$\", line)\n",
    "        if location_match:\n",
    "            current_location = location_match.group(1).strip()\n",
    "            location_data = {\n",
    "                \"description\": \"\",\n",
    "                \"factions\": [],\n",
    "                \"city_manager\": None,\n",
    "                \"security_provider\": None,\n",
    "                \"npcs_present\": [],\n",
    "                \"events\": [],\n",
    "                \"sub_locations\": {},\n",
    "                \"region\": current_region\n",
    "            }\n",
    "\n",
    "            # Read location description\n",
    "            i += 1\n",
    "            desc_lines = []\n",
    "            while i < len(lines) and not lines[i].startswith(\"CITY MANAGER:\"):\n",
    "                desc_lines.append(lines[i])\n",
    "                i += 1\n",
    "            location_data[\"description\"] = \" \".join(desc_lines).strip()\n",
    "\n",
    "            # Manager\n",
    "            if i < len(lines) and lines[i].startswith(\"CITY MANAGER:\"):\n",
    "                location_data[\"city_manager\"] = lines[i].split(\":\", 1)[1].strip()\n",
    "                i += 1\n",
    "\n",
    "            # Security\n",
    "            if i < len(lines) and lines[i].startswith(\"SECURITY PROVIDER:\"):\n",
    "                location_data[\"security_provider\"] = lines[i].split(\":\", 1)[1].strip()\n",
    "                i += 1\n",
    "\n",
    "            # Gangs\n",
    "            if i < len(lines) and lines[i].startswith(\"GANGS PRESENT:\"):\n",
    "                gangs = lines[i].split(\":\", 1)[1]\n",
    "                location_data[\"factions\"] = [g.strip() for g in gangs.split(\",\")]\n",
    "                i += 1\n",
    "\n",
    "            # Sublocations\n",
    "            if i < len(lines) and \"LOCATIONS\" in lines[i]:\n",
    "                i += 1\n",
    "                while i < len(lines) and re.match(r\"^\\([A-Z]\\d+\\)\", lines[i]):\n",
    "                    sub_match = re.match(r\"^\\(([A-Z]\\d+)\\)\\s+(.+?):\\s+(.+)\", lines[i])\n",
    "                    if sub_match:\n",
    "                        _, title, desc = sub_match.groups()\n",
    "                        location_data[\"sub_locations\"][title.title()] = desc.strip().capitalize()\n",
    "                    i += 1\n",
    "\n",
    "            # Save location entry\n",
    "            world[\"locations\"][current_location] = location_data\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return world\n",
    "def save_world_state(world, output_path):\n",
    "    Path(\"campaign\").mkdir(exist_ok=True)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(world, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"✅ World state saved to {output_path}\")"
   ],
   "id": "56e779972efc29f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "world_data = parse_world_text_upper(INPUT_FILE)\n",
    "save_world_state(world_data, OUTPUT_FILE)"
   ],
   "id": "f6d4fc4bf1d4e4d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## WORLD RAG",
   "id": "22ffe92dc0f39cd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T00:57:21.489479Z",
     "start_time": "2025-06-27T00:57:21.482421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "\n",
    "def build_rag_chunks(world):\n",
    "    chunks = []\n",
    "\n",
    "    for loc_name, loc_data in world[\"locations\"].items():\n",
    "        # Main location entry\n",
    "        chunks.append({\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"text\": f\"{loc_name}: {loc_data['description']}\",\n",
    "            \"metadata\": {\n",
    "                \"region\": loc_data.get(\"region\"),\n",
    "                \"location\": loc_name,\n",
    "                \"type\": \"location\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # Sub-locations\n",
    "        for sub_name, sub_desc in loc_data.get(\"sub_locations\", {}).items():\n",
    "            chunks.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"text\": f\"{sub_name}: {sub_desc}\",\n",
    "                \"metadata\": {\n",
    "                    \"region\": loc_data.get(\"region\"),\n",
    "                    \"location\": loc_name,\n",
    "                    \"sublocation\": sub_name,\n",
    "                    \"type\": \"sublocation\"\n",
    "                }\n",
    "            })\n",
    "\n",
    "    return chunks"
   ],
   "id": "c7b9ec4941cec353",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "client = chromadb.PersistentClient(path=\"./vectordb\")\n",
    "collection = client.get_or_create_collection(\"night_city_locations\")\n",
    "\n",
    "rag_chunks = build_rag_chunks(world_data)\n",
    "\n",
    "for chunk in rag_chunks:\n",
    "    embedding = model.encode(chunk[\"text\"]).tolist()\n",
    "    collection.add(\n",
    "        ids=[chunk[\"id\"]],\n",
    "        embeddings=[embedding],\n",
    "        documents=[chunk[\"text\"]],\n",
    "        metadatas=[chunk[\"metadata\"]]\n",
    "    )\n",
    "\n",
    "print(f\"✅ Indexed {len(rag_chunks)} chunks.\")"
   ],
   "id": "642f93edb395dc81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T00:57:53.945158Z",
     "start_time": "2025-06-27T00:57:53.846221Z"
    }
   },
   "cell_type": "code",
   "source": "client.get_or_create_collection(\"night_city_locations\")",
   "id": "f4e4d5d7c6bdbaa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['2029eb31-cf12-471a-a9ef-cac86a682862',\n",
       "  '071d2894-33e0-4cd0-a3df-7c41cb18d4fb',\n",
       "  'c8e12a71-8a5c-4597-b612-90912ff4d35f',\n",
       "  '9b76fdfc-6932-4158-bbe2-65963c50c277',\n",
       "  'ce733234-c773-4ed8-83e7-77b5592de0ba',\n",
       "  'f300598c-cfc6-4a6c-a20e-df0670fae643',\n",
       "  '55a664dc-2f84-41f6-b199-9dcf13053183',\n",
       "  '25d92ee0-39da-4fb1-8f4a-71bedabec354',\n",
       "  '7808a837-b2f8-47c3-8a23-1fa4ac62a5af',\n",
       "  'd6de38a3-68e8-40f0-ab77-86be1fa2cf59'],\n",
       " 'embeddings': array([[ 0.08824068,  0.0775604 , -0.03163269, ...,  0.04255744,\n",
       "         -0.05548633,  0.08193853],\n",
       "        [ 0.01131884,  0.08527941,  0.02205821, ...,  0.0275717 ,\n",
       "         -0.01869821,  0.04943081],\n",
       "        [-0.09070063,  0.02243145, -0.04655228, ..., -0.01629366,\n",
       "         -0.0125857 ,  0.0195929 ],\n",
       "        ...,\n",
       "        [ 0.0191662 ,  0.03951368, -0.01767524, ...,  0.00370416,\n",
       "          0.05089001,  0.02286817],\n",
       "        [-0.00567449, -0.04538913, -0.02788978, ...,  0.0116009 ,\n",
       "         -0.09213474,  0.02040352],\n",
       "        [ 0.05858824,  0.05028891, -0.05996007, ..., -0.05103894,\n",
       "          0.03911541,  0.03053044]], shape=(10, 384)),\n",
       " 'documents': ['LITTLE EUROPE: A DISTRICT DIVIDED BETWEEN CLASSES AND TIMES, WITH OLD BRICK BUILDINGS STANDING NEXT TO FUTURISTIC SKYSCRAPERS.',\n",
       "  'Camden Court: A secure apartment complex favored by solos and execs.',\n",
       "  'Chopper’S: Formerly a butcher’s shop, now a bar. the meat grinder still works if you want to get rid of a body.',\n",
       "  'Continental   Brands   Vertical Neighborhood: Housing for continental brands employees. a nightmare to navigate due to its “flavors of the world” theming.',\n",
       "  'Cube-A-Rama: A cube hotel with an original brick exterior.',\n",
       "  'Danger Gal Housing Facility: Housing for danger gal employees. pink and full of life.',\n",
       "  'Danger Gal Offices: Home base for danger gal, a private investigation and security neocorp.',\n",
       "  'Fiddler’S Green: An “irish” pub that’s about as irish as green beer on saint patty’s day.',\n",
       "  'Greta’S: The best pool hall in night city, with a strong lesbian client base.',\n",
       "  'Holy Angels Church: A catholic church run by father kevin and father paul. known far and wide as neutral ground in night city.'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'embeddings'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'type': 'location',\n",
       "   'region': 'THE ISLAND',\n",
       "   'location': 'LITTLE EUROPE'},\n",
       "  {'region': 'THE ISLAND',\n",
       "   'location': 'LITTLE EUROPE',\n",
       "   'sublocation': 'Camden Court',\n",
       "   'type': 'sublocation'},\n",
       "  {'type': 'sublocation',\n",
       "   'location': 'LITTLE EUROPE',\n",
       "   'sublocation': 'Chopper’S',\n",
       "   'region': 'THE ISLAND'},\n",
       "  {'region': 'THE ISLAND',\n",
       "   'type': 'sublocation',\n",
       "   'sublocation': 'Continental   Brands   Vertical Neighborhood',\n",
       "   'location': 'LITTLE EUROPE'},\n",
       "  {'location': 'LITTLE EUROPE',\n",
       "   'type': 'sublocation',\n",
       "   'sublocation': 'Cube-A-Rama',\n",
       "   'region': 'THE ISLAND'},\n",
       "  {'sublocation': 'Danger Gal Housing Facility',\n",
       "   'type': 'sublocation',\n",
       "   'location': 'LITTLE EUROPE',\n",
       "   'region': 'THE ISLAND'},\n",
       "  {'type': 'sublocation',\n",
       "   'location': 'LITTLE EUROPE',\n",
       "   'region': 'THE ISLAND',\n",
       "   'sublocation': 'Danger Gal Offices'},\n",
       "  {'location': 'LITTLE EUROPE',\n",
       "   'sublocation': 'Fiddler’S Green',\n",
       "   'region': 'THE ISLAND',\n",
       "   'type': 'sublocation'},\n",
       "  {'sublocation': 'Greta’S',\n",
       "   'region': 'THE ISLAND',\n",
       "   'type': 'sublocation',\n",
       "   'location': 'LITTLE EUROPE'},\n",
       "  {'region': 'THE ISLAND',\n",
       "   'type': 'sublocation',\n",
       "   'sublocation': 'Holy Angels Church',\n",
       "   'location': 'LITTLE EUROPE'}]}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 160
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def route_query(query: str) -> list[str]:\n",
    "    keywords = {\n",
    "        \"rules\": [\"dv\", \"roll\", \"damage\", \"cyberware\", \"initiative\", \"skill\", \"autofire\", \"check\", \"attack\", \"armor\"],\n",
    "        \"world\": [\"location\", \"where\", \"district\", \"gang\", \"building\", \"club\", \"bar\", \"clinic\", \"neighborhood\", \"city\"]\n",
    "    }\n",
    "\n",
    "    query_lc = query.lower()\n",
    "    used_sources = []\n",
    "\n",
    "    if any(kw in query_lc for kw in keywords[\"rules\"]):\n",
    "        used_sources.append(\"cpr_core_rules\")\n",
    "    if any(kw in query_lc for kw in keywords[\"world\"]):\n",
    "        used_sources.append(\"night_city_locations\")\n",
    "\n",
    "    # If nothing matched, include both\n",
    "    if not used_sources:\n",
    "        used_sources = [\"cpr_core_rules\", \"night_city_locations\"]\n",
    "\n",
    "    return used_sources"
   ],
   "id": "f24fc933938cd035",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ask_gpt4o_with_context(user_query: str, context_text: str, system_prompt: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"{user_query}\\n\\nContext:\\n{context_text}\"}\n",
    "    ]\n",
    "\n",
    "    response = client_open_ai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.4\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ],
   "id": "e075e26c9904912c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def query_with_context(query: str, k: int = 4):\n",
    "    source_names = route_query(query)\n",
    "    all_contexts = []\n",
    "\n",
    "    for name in source_names:\n",
    "        collection = client.get_collection(name)\n",
    "        embedding = model.encode(query).tolist()\n",
    "        results = collection.query(query_embeddings=[embedding], n_results=k)\n",
    "\n",
    "        docs = results[\"documents\"][0]\n",
    "        metadatas = results[\"metadatas\"][0]\n",
    "\n",
    "        for doc, meta in zip(docs, metadatas):\n",
    "            label = (\n",
    "                meta.get(\"chapter\") + f\" – p.{meta.get('page')}\"\n",
    "                if \"chapter\" in meta and \"page\" in meta else\n",
    "                meta.get(\"location\", name).title()\n",
    "            )\n",
    "            all_contexts.append(f\"[{label}]\\n{doc}\")\n",
    "\n",
    "    context_text = \"\\n\\n\".join(all_contexts)\n",
    "\n",
    "    # Pick system prompt dynamically\n",
    "    if \"cpr_core_rules\" in source_names and len(source_names) == 1:\n",
    "        system_prompt = (\n",
    "            \"You are a Cyberpunk RED game assistant. Answer the user's question \"\n",
    "            \"using only the official rules. Include relevant citations (e.g., page number and chapter). \"\n",
    "            \"If the rules are unclear, say so rather than guessing.\"\n",
    "        )\n",
    "    else:\n",
    "        system_prompt = (\n",
    "            \"You are a Cyberpunk RED game assistant. Use the context below to answer the user's question truthfully. \"\n",
    "            \"If the context is from the rules, cite the mechanic. If it's from the world, describe it accurately.\"\n",
    "        )\n",
    "\n",
    "    return ask_gpt4o_with_context(query, context_text, system_prompt)"
   ],
   "id": "53b8a4d7a72bdb25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "query_with_context(\"Based on the rules, how far is it to get to Afterlife from The Glen?\")",
   "id": "dead49381c56bd54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "def parse_weapon_table(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    rows = root.findall(\".//row\")\n",
    "    weapons = []\n",
    "\n",
    "    current_category = None\n",
    "\n",
    "    for row in rows:\n",
    "        cells = [cell.text.strip() if cell.text else \"\" for cell in row.findall(\"cell\")]\n",
    "\n",
    "        # Skip empty rows\n",
    "        if not any(cells):\n",
    "            continue\n",
    "\n",
    "        # Category row example: \"Medium Pistols\"\n",
    "        if len(cells) == 1 and cells[0].isupper() == False and len(cells[0].split()) <= 3:\n",
    "            current_category = cells[0]\n",
    "            print(current_category)\n",
    "            continue\n",
    "\n",
    "        # Weapon rows: expect at least name, cost, source\n",
    "        non_empty = [c for c in cells if c]\n",
    "        if len(non_empty) >= 3 and any(\"eb\" in c.lower() for c in non_empty):\n",
    "            weapon = {\n",
    "                \"name\": non_empty[0],\n",
    "                \"cost\": next((c for c in non_empty if \"eb\" in c.lower()), \"\"),\n",
    "                \"source\": next((c for c in non_empty if \"CP:\" in c or \"DL:\" in c or \"IR\" in c or \"MC\" in c or \"DGD\" in c or \"CEMK\" in c or \"BC\" in c), \"\"),\n",
    "                \"category\": current_category\n",
    "            }\n",
    "            weapons.append(weapon)\n",
    "\n",
    "    return weapons\n",
    "\n",
    "weapons = parse_weapon_table(\"item_index_1.xml\")\n",
    "\n",
    "with open(\"night_market.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(weapons, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Extracted {len(weapons)} weapons to night_market.json\")"
   ],
   "id": "a37072bf924d6998",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "core_book = pymupdf.open(\"TalesOfRed.pdf\")\n",
    "chunks = []\n",
    "toc = core_book.get_toc(simple=True)\n",
    "page_map = {}\n",
    "toc_index = 0\n",
    "for page_num in range(len(core_book)):\n",
    "        while toc_index + 1 < len(toc) and toc[toc_index + 1][2] <= page_num + 1:\n",
    "            toc_index += 1\n",
    "        page_map[page_num] = toc[toc_index][1] if toc else \"Unknown\"\n",
    "page_map"
   ],
   "id": "9201ebfaf8ec4687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "stories = [\"Night \"]",
   "id": "aa1e3a0eaefa917d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "toc",
   "id": "ce627c47c15dfe8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
